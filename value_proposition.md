# Value Proposition — AnimalTaskSim

**Tagline:** A defensible yardstick for “animal-like” behavior in AI.

## For whom
- **Neuroscience & cognitive labs** — validate computational models against standardized tasks and metrics.
- **RL/AI researchers** — claim “animal-like” with evidence that survives reviewer scrutiny.
- **Educators** — run lab-grade experiments in a classroom with reproducible outputs.

## Core value
- **Task fidelity**: environments mirror real rodent/primate paradigms (trial phases, timings, priors).  
- **Fingerprint metrics**: psychometric/chronometric curves, history kernels, lapses, training dynamics.  
- **Reproducible scoring**: unified logging schema + HTML reports that recreate canonical figures.

## Differentiators
- Not just a task library; **a benchmark** with clear pass/fail criteria against animal-style statistics.  
- **Agent-agnostic**: any policy can be graded if it writes logs to the schema.  
- **Lightweight & CPU-friendly**: demo runs complete in minutes.

## Why now
Open animal-behavior datasets and standardized protocols exist; AI is hungry for credible, human/animal-aligned benchmarks. The gap is a product that turns scattered methods into a reusable, public yardstick.

## Business angles
- **Hosted evaluation & leaderboard** (paid): upload logs → get DOI-citable report & ranking.  
- **Academic/enterprise licensing**: premium validation suites, long-run experiments, SSO, private leaderboards.  
- **Training/EdTech**: course kits and workshops.

## Proof points (MVP)
- Two canonical tasks, three baselines, reports that highlight where agents fail and what inductive biases close the gap.
